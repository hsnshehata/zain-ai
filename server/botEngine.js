// /server/botEngine.js

const OpenAI = require('openai');
const mongoose = require('mongoose');
const axios = require('axios');
const FormData = require('form-data');
const Bot = require('./models/Bot');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const conversationSchema = new mongoose.Schema({
  botId: { type: mongoose.Schema.Types.ObjectId, ref: 'Bot', required: true },
  userId: { type: String, required: true },
  messages: [
    {
      role: { type: String, enum: ['user', 'assistant'], required: true },
      content: { type: String, required: true },
      timestamp: { type: Date, default: Date.now },
    },
  ],
});

const Conversation = mongoose.model('Conversation', conversationSchema);

const Rule = require('./models/Rule');

async function transcribeAudio(audioUrl) {
  const body = new FormData();
  body.append('file', audioUrl);
  body.append('language', 'arabic');
  body.append('response_format', 'json');
  try {
    console.log(
      'LemonFox API Key: ' +
        (process.env.LEMONFOX_API_KEY ? 'ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­' : 'Ø§Ù„Ù…ÙØªØ§Ø­ ÙØ§Ø¶ÙŠ!')
    );
    const response = await axios.post(
      'https://api.lemonfox.ai/v1/audio/transcriptions',
      body,
      {
        headers: {
          Authorization: `Bearer ${process.env.LEMONFOX_API_KEY}`,
          ...body.getHeaders(),
        },
      }
    );
    console.log('âœ… Audio transcribed with LemonFox:', response.data.text);
    return response.data.text;
  } catch (err) {
    console.error('âŒ Error transcribing audio with LemonFox:', err.message, err.stack);
    throw new Error(`Failed to transcribe audio: ${err.message}`);
  }
}

async function processMessage(botId, userId, message, isImage = false, isVoice = false) {
  try {
    console.log('ðŸ¤– Processing message for bot:', botId, 'user:', userId, 'message:', message);

    const rules = await Rule.find({ $or: [{ botId }, { type: 'global' }] });
    console.log('ðŸ“œ Rules found:', rules);

    let systemPrompt = 'Ø£Ù†Øª Ø¨ÙˆØª Ø°ÙƒÙŠ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©:\n';
    if (rules.length === 0) {
      systemPrompt += 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ù… Ø¨Ø§Ù„Ø±Ø¯ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… ÙˆÙ…ÙÙŠØ¯.\n';
    } else {
      rules.forEach((rule) => {
        if (rule.type === 'global' || rule.type === 'general') {
          systemPrompt += `${rule.content}\n`;
        } else if (rule.type === 'products') {
          systemPrompt += `Ø§Ù„Ù…Ù†ØªØ¬: ${rule.content.product}ØŒ Ø§Ù„Ø³Ø¹Ø±: ${rule.content.price} ${rule.content.currency}\n`;
        } else if (rule.type === 'qa') {
          systemPrompt += `Ø§Ù„Ø³Ø¤Ø§Ù„: ${rule.content.question}ØŒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: ${rule.content.answer}\n`;
        }
      });
    }
    console.log('ðŸ“ System prompt:', systemPrompt);

    let conversation = await Conversation.findOne({ botId, userId });
    if (!conversation) {
      console.log('ðŸ“‹ Creating new conversation for bot:', botId, 'user:', userId);
      conversation = await Conversation.create({ botId, userId, messages: [] });
    } else {
      console.log('ðŸ“‹ Found existing conversation:', conversation._id);
    }

    let userMessageContent = message;

    if (isVoice) {
      userMessageContent = await transcribeAudio(message);
      if (!userMessageContent) {
        throw new Error('Failed to transcribe audio: No text returned');
      }
      console.log('ðŸ’¬ Transcribed audio message:', userMessageContent);
    }

    // Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø§Ù„Ù€ timestamp
    conversation.messages.push({ role: 'user', content: userMessageContent, timestamp: new Date() });
    await conversation.save();
    console.log('ðŸ’¬ User message added to conversation:', userMessageContent);

    // Ø¬Ù„Ø¨ ÙˆÙ‚Øª Ø¢Ø®Ø± Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    const lastUserMessage = conversation.messages
      .filter(msg => msg.role === 'user')
      .sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp))[0];
    const lastMessageTimestamp = lastUserMessage ? new Date(lastUserMessage.timestamp) : new Date();

    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversation.messages.map((msg) => ({ role: msg.role, content: msg.content })),
    ];

    if (isImage) {
      messages.push({
        role: 'user',
        content: [
          { type: 'text', text: 'Analyze this image:' },
          { type: 'image_url', image_url: { url: message } },
        ],
      });
      console.log('ðŸ–¼ï¸ Processing image message');
    }

    console.log('ðŸ“¡ Calling OpenAI API...');
    let reply = '';
    let matchedRuleId = null;

    // Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„
    if (message.includes('Ø§Ù†ØªÙˆØ§ ÙØ§ØªØ­ÙŠÙ†') || message.includes('Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„')) {
      // ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI
      const timePrompt = `
        Ø£Ù†Øª Ø¨ÙˆØª Ø°ÙƒÙŠ. Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø¯ ØªØªØ¶Ù…Ù† Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„:
        ${systemPrompt}
        Ø§Ù„Ø³Ø¤Ø§Ù„: "${message}"
        Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ (Ù…Ø«Ù„ "Ù…Ù† 9 Ø§Ù„ØµØ¨Ø­ Ù„Ù€ 5 Ø§Ù„Ù…ØºØ±Ø¨" Ø£Ùˆ "Ù…Ù† Ø§Ù„Ø³Ø§Ø¹Ø© 8 Ù„Ù„Ø³Ø§Ø¹Ø© 6") Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯.
        Ù„Ùˆ Ù„Ù‚ÙŠØª Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ØŒ Ø±Ø¬Ø¹Ù‡Ø§ ÙÙŠ ØµÙŠØºØ©: "Ù…Ù† HH:MM Ø¥Ù„Ù‰ HH:MM" (Ø¨ØªÙˆÙ‚ÙŠØª 24 Ø³Ø§Ø¹Ø©).
        Ù„Ùˆ Ù…Ø§ Ù„Ù‚ÙŠØªØ´ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ØŒ Ø±Ø¬Ø¹: "Ù„Ù… Ø£Ø¬Ø¯ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯."
      `;

      const timeResponse = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [{ role: 'system', content: timePrompt }],
        max_tokens: 100,
      });

      let workingHoursText = timeResponse.choices[0].message.content;
      let workingHours = { start: '09:00', end: '17:00' }; // Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ùˆ Ù…Ø§ Ù„Ù‚ÙŠÙ†Ø§Ø´ Ù…ÙˆØ§Ø¹ÙŠØ¯

      if (workingHoursText !== 'Ù„Ù… Ø£Ø¬Ø¯ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯.') {
        // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† Ø§Ù„Ù†Øµ (Ù…Ø«Ø§Ù„: "Ù…Ù† 09:00 Ø¥Ù„Ù‰ 17:00")
        const match = workingHoursText.match(/Ù…Ù† (\d{2}:\d{2}) Ø¥Ù„Ù‰ (\d{2}:\d{2})/);
        if (match) {
          workingHours.start = match[1];
          workingHours.end = match[2];
        }

        // Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ø´Ø§Ù† Ù†Ø²ÙˆÙ‘Ø¯ usageCount
        const matchedRule = rules.find(rule => 
          (rule.type === 'general' || rule.type === 'global') && 
          rule.content.includes(workingHoursText)
        );
        if (matchedRule) {
          matchedRuleId = matchedRule._id;
        }
      } else {
        reply = 'Ù„Ù… Ø£Ø¬Ø¯ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯. ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙŠ!';
      }

      // Ø¥Ø°Ø§ Ù„Ù‚ÙŠÙ†Ø§ Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø¹Ù…Ù„ØŒ Ù†Ø­Ø³Ø¨ Ø¥Ø°Ø§ Ø§Ù„Ø¨ÙˆØª "ÙØ§ØªØ­" Ø£Ùˆ "Ù…ØºÙ„Ù‚"
      if (!reply) {
        const now = lastMessageTimestamp;
        const startTime = new Date(now.toDateString() + ' ' + workingHours.start);
        const endTime = new Date(now.toDateString() + ' ' + workingHours.end);
        const isOpen = now >= startTime && now <= endTime;

        reply = `Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ Ù…Ù† ${workingHours.start} Ø¥Ù„Ù‰ ${workingHours.end}. Ø§Ù„ÙˆÙ‚Øª Ø¯Ù„ÙˆÙ‚ØªÙŠ ${lastMessageTimestamp.toLocaleString('ar-EG')}. ${isOpen ? 'Ø¥Ø­Ù†Ø§ ÙØ§ØªØ­ÙŠÙ† Ø¯Ù„ÙˆÙ‚ØªÙŠ!' : 'Ù„Ù„Ø£Ø³Ù Ø¥Ø­Ù†Ø§ Ù…ØºÙ„Ù‚ÙŠÙ† Ø¯Ù„ÙˆÙ‚ØªÙŠ.'}`;
      }
    } else {
      // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø´ Ø¹Ù† Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„ØŒ Ù†ÙƒÙ…Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ø¯ÙŠ
      // Ù†Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ù‚Ø¨Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
      for (const rule of rules) {
        if (rule.type === 'qa' && userMessageContent.toLowerCase().includes(rule.content.question.toLowerCase())) {
          matchedRuleId = rule._id;
          reply = rule.content.answer;
          break;
        } else if (rule.type === 'general' || rule.type === 'global') {
          if (userMessageContent.toLowerCase().includes(rule.content.toLowerCase())) {
            matchedRuleId = rule._id;
            reply = rule.content;
            break;
          }
        } else if (rule.type === 'products') {
          if (userMessageContent.toLowerCase().includes(rule.content.product.toLowerCase())) {
            matchedRuleId = rule._id;
            reply = `Ø§Ù„Ù…Ù†ØªØ¬: ${rule.content.product}ØŒ Ø§Ù„Ø³Ø¹Ø±: ${rule.content.price} ${rule.content.currency}`;
            break;
          }
        }
      }

      // Ø¥Ø°Ø§ Ù…Ø§ Ù„Ù‚ÙŠÙ†Ø§Ø´ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø©ØŒ Ù†Ø³ØªØ¯Ø¹ÙŠ OpenAI
      if (!reply) {
        const response = await openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages,
          max_tokens: 700,
        });
        reply = response.choices[0].message.content;
      }
    }

    // Ø²ÙŠØ§Ø¯Ø© usageCount Ù„Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª)
    if (matchedRuleId) {
      await Rule.updateOne({ _id: matchedRuleId }, { $inc: { usageCount: 1 } });
      console.log(`ðŸ“ˆ Incremented usageCount for rule: ${matchedRuleId}`);
    }

    // Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© ÙÙŠ Ø§Ù„Ø±Ø¯
    if (reply.includes('${lastMessageTimestamp.toLocaleString(\'ar-EG\')}')) {
      reply = reply.replace('${lastMessageTimestamp.toLocaleString(\'ar-EG\')}', lastMessageTimestamp.toLocaleString('ar-EG'));
    }
    if (reply.includes('${lastMessageTimestamp.toISOString()}')) {
      reply = reply.replace('${lastMessageTimestamp.toISOString()}', lastMessageTimestamp.toISOString());
    }

    conversation.messages.push({ role: 'assistant', content: reply, timestamp: new Date() });
    await conversation.save();
    console.log('ðŸ’¬ Assistant reply added to conversation:', reply);

    return reply;
  } catch (err) {
    console.error('âŒ Error processing message:', err.message, err.stack);
    return 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ.';
  }
}

module.exports = { processMessage };
