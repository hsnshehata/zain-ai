const OpenAI = require('openai');
const mongoose = require('mongoose');
const axios = require('axios');
const FormData = require('form-data');
const Bot = require('./models/Bot');
const Rule = require('./models/Rule');
const Conversation = require('./models/Conversation');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Ø¯Ø§Ù„Ø© Ù„Ø¬Ù„Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ
function getCurrentTime() {
  return new Date().toLocaleString('ar-EG', { timeZone: 'Africa/Cairo' });
}

async function transcribeAudio(audioUrl) {
  const body = new FormData();
  body.append('file', audioUrl);
  body.append('language', 'arabic');
  body.append('response_format', 'json');
  try {
    console.log(
      'LemonFox API Key: ' +
        (process.env.LEMONFOX_API_KEY ? 'ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­' : 'Ø§Ù„Ù…ÙØªØ§Ø­ ÙØ§Ø¶ÙŠ!')
    );
    const response = await axios.post(
      'https://api.lemonfox.ai/v1/audio/transcriptions',
      body,
      {
        headers: {
          Authorization: `Bearer ${process.env.LEMONFOX_API_KEY}`,
          ...body.getHeaders(),
        },
      }
    );
    console.log('âœ… Audio transcribed with LemonFox:', response.data.text);
    return response.data.text;
  } catch (err) {
    console.error('âŒ Error transcribing audio with LemonFox:', err.message, err.stack);
    throw new Error(`Failed to transcribe audio: ${err.message}`);
  }
}

async function processMessage(botId, userId, message, isImage = false, isVoice = false) {
  try {
    console.log('ğŸ¤– Processing message for bot:', botId, 'user:', userId, 'message:', message);

    let conversation = await Conversation.findOne({ botId, userId });
    if (!conversation) {
      console.log('ğŸ“‹ Creating new conversation for bot:', botId, 'user:', userId);
      conversation = await Conversation.create({ botId, userId, messages: [] });
    } else {
      console.log('ğŸ“‹ Found existing conversation:', conversation._id);
    }

    // ÙØ­Øµ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø±Ø³Ø§Ù„Ø©
    const messageKey = `${message}-${Date.now()}`;
    if (conversation.messages.some(msg => 
      msg.content === message && 
      Math.abs(new Date(msg.timestamp) - Date.now()) < 1000
    )) {
      console.log(`âš ï¸ Duplicate message detected in conversation for ${userId}, skipping...`);
      return 'ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‡Ø°Ù‡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ù‚Ø¨Ù„';
    }

    const rules = await Rule.find({ $or: [{ botId }, { type: 'global' }] });
    console.log('ğŸ“œ Rules found:', rules);

    // Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ systemPrompt Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ
    let systemPrompt = `Ø£Ù†Øª Ø¨ÙˆØª Ø°ÙƒÙŠ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©. Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‡Ùˆ: ${getCurrentTime()}.\n`;
    if (rules.length === 0) {
      systemPrompt += 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ù… Ø¨Ø§Ù„Ø±Ø¯ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… ÙˆÙ…ÙÙŠØ¯.\n';
    } else {
      rules.forEach((rule) => {
        if (rule.type === 'global' || rule.type === 'general') {
          systemPrompt += `${rule.content}\n`;
        } else if (rule.type === 'products') {
          systemPrompt += `Ø§Ù„Ù…Ù†ØªØ¬: ${rule.content.product}ØŒ Ø§Ù„Ø³Ø¹Ø±: ${rule.content.price} ${rule.content.currency}\n`;
        } else if (rule.type === 'qa') {
          systemPrompt += `Ø§Ù„Ø³Ø¤Ø§Ù„: ${rule.content.question}ØŒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: ${rule.content.answer}\n`;
        } else if (rule.type === 'channels') {
          systemPrompt += `Ù‚Ù†Ø§Ø© Ø§Ù„ØªÙˆØ§ØµÙ„: ${rule.content.platform}ØŒ Ø§Ù„ÙˆØµÙ: ${rule.content.description}ØŒ Ø§Ù„Ø±Ø§Ø¨Ø·/Ø§Ù„Ø±Ù‚Ù…: ${rule.content.value}\n`;
        }
      });
    }
    console.log('ğŸ“ System prompt:', systemPrompt);

    let userMessageContent = message;

    if (isVoice) {
      userMessageContent = await transcribeAudio(message);
      if (!userMessageContent) {
        throw new Error('Failed to transcribe audio: No text returned');
      }
      console.log('ğŸ’¬ Transcribed audio message:', userMessageContent);
    }

    conversation.messages.push({ role: 'user', content: userMessageContent, timestamp: new Date() });
    await conversation.save();
    console.log('ğŸ’¬ User message added to conversation:', userMessageContent);

    let reply = '';

    // Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ù‚Ø¨Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
    for (const rule of rules) {
      if (rule.type === 'qa' && userMessageContent.toLowerCase().includes(rule.content.question.toLowerCase())) {
        reply = rule.content.answer;
        break;
      } else if (rule.type === 'general' || rule.type === 'global') {
        if (userMessageContent.toLowerCase().includes(rule.content.toLowerCase())) {
          reply = rule.content;
          break;
        }
      } else if (rule.type === 'products') {
        if (userMessageContent.toLowerCase().includes(rule.content.product.toLowerCase())) {
          reply = `Ø§Ù„Ù…Ù†ØªØ¬: ${rule.content.product}ØŒ Ø§Ù„Ø³Ø¹Ø±: ${rule.content.price} ${rule.content.currency}`;
          break;
        }
      } else if (rule.type === 'channels') {
        if (userMessageContent.toLowerCase().includes(rule.content.platform.toLowerCase())) {
          reply = `Ù‚Ù†Ø§Ø© Ø§Ù„ØªÙˆØ§ØµÙ„: ${rule.content.platform}\nØ§Ù„ÙˆØµÙ: ${rule.content.description}\nØ§Ù„Ø±Ø§Ø¨Ø·/Ø§Ù„Ø±Ù‚Ù…: ${rule.content.value}`;
          break;
        }
      }
    }

    // Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø©ØŒ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
    if (!reply) {
      if (isImage) {
        // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… responses.create Ù…Ø¹ input
        const response = await openai.responses.create({
          model: 'gpt-4.1-mini-2025-04-14',
          input: [
            { role: 'system', content: systemPrompt },
            ...conversation.messages.map((msg) => ({ role: msg.role, content: msg.content })),
            {
              role: 'user',
              content: [
                { type: 'input_text', text: 'Ø§Ø·Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©' },
                { type: 'input_image', image_url: message },
              ],
            },
          ],
          max_output_tokens: 5000,
        });
        reply = response.output_text || 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.';
        console.log('ğŸ–¼ï¸ Image processed:', reply);
      } else {
        // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… chat.completions.create
        const messages = [
          { role: 'system', content: systemPrompt },
          ...conversation.messages.map((msg) => ({ role: msg.role, content: msg.content })),
        ];
        const response = await openai.chat.completions.create({
          model: 'gpt-4.1-mini-2025-04-14',
          messages,
          max_tokens: 5000,
        });
        reply = response.choices[0].message.content;
      }
    }

    conversation.messages.push({ role: 'assistant', content: reply, timestamp: new Date() });
    await conversation.save();
    console.log('ğŸ’¬ Assistant reply added to conversation:', reply);

    return reply;
  } catch (err) {
    console.error('âŒ Error processing message:', err.message, err.stack);
    return 'Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ.';
  }
}

module.exports = { processMessage };
